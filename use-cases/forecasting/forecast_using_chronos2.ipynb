{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d255121-8caf-4a88-a800-e9ee3099502f",
   "metadata": {},
   "source": [
    "# Forecasting using Large Language Model (Amazon Chronos-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b0487-8d88-4922-a1cc-548a446f2e2b",
   "metadata": {},
   "source": [
    "## Install Required Packages and import libraries\n",
    "### We are using chronos2 model from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43cbed-5ffa-48a3-95ab-8e617e2ddc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'pandas[pyarrow]\n",
    "!pip install \"chronos-forecasting>=2.0\"\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c727a6-890e-4626-b718-e4e155b0c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from chronos import Chronos2Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1c871-b4c5-42f1-87fd-e2eb74250495",
   "metadata": {},
   "source": [
    "## Load Historical Timeseries data\n",
    "### In this example, we are using hourly room temprature data \n",
    "### the dataset should have minimum three columns\n",
    "    - key/id - item for which forecast is to be made\n",
    "    - datatime - timeseries column\n",
    "    - target - value for which prediction is to be made\n",
    "### In the example below, we are modifying the timeseries data to add key/id field and remove unused fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6af59f-68af-4a96-b1e3-d77664a38037",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.read_csv(\"room_temperature.csv\")\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37117e8-9d1b-4a86-b791-948a7cebb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = mydf.drop(columns=['id', 'Datetime1'])\n",
    "mydf[\"key\"] = \"room\"\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8f0e0-1861-4321-b043-c6f69729b8a2",
   "metadata": {},
   "source": [
    "## Prepare context Data\n",
    "### Context data is used to provide context to LLM model to learn pattern to make forecast\n",
    "### In this example, out of 6676 rows, we are taking  first 6652 rows as context data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37204caf-37b6-4cfa-a3d9-e196e72cdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e27ba2-bf67-4bcc-baea-f657dc3e4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = mydf.head(6652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de5c12-6e64-45c5-a7bc-a50269907827",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2efbbe-6f52-4c86-b6f5-ba8229dba5b9",
   "metadata": {},
   "source": [
    "## Prepare Feature Data\n",
    "### feature data is the data for which prediction or forecast is made by the LLM\n",
    "### In this example, out of 6676 rows, we are taking last 24 hows rows as feature data\n",
    "### since, LLM has to make forecast, we remove target field from the feature data\n",
    "### We still keep test_df (different data frame than feature) as it holds last 24 rows with target field and it can be used to compare actual vs. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4581ec-5f37-4a8b-8423-ba6de3eee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = mydf.tail(24)\n",
    "\n",
    "future_df = test_df.drop(columns=\"target\")\n",
    "future_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502c145-99b7-4eed-9255-e8a32a84535f",
   "metadata": {},
   "source": [
    "## Load Model Weights and Make Prediction from HuggingFace (alternative, you can deploy model to Amazon SageMaker and infer from there)\n",
    "### Prediction takes the following parameter\n",
    "    - Context data frame - data frame holding context data\n",
    "    - feature data frame - data frame with rows for which predicion is made\n",
    "    - prediction_length - prediction forcast timeline. For instance, in this example, we need prediction for 24 rows, so prediction lenght is 24.\n",
    "    - quantile_levels - from 0.1 to 0.9. In this example - we take three - [0.1, 0.5, 0.9]\n",
    "    - id_column - item for which forecast is to be made\n",
    "    - timestamp_column - timeseries column\n",
    "    - target - Column(s) with timeseries values to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b9b75-f75d-41ba-bf4e-015c6a5a0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Chronos2Pipeline.from_pretrained(\"amazon/chronos-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea10524-38cf-401b-8538-043db904d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pipeline.predict_df(\n",
    "    context_df,\n",
    "    future_df=future_df,\n",
    "    prediction_length=24,  \n",
    "    quantile_levels=[0.1, 0.5, 0.9],  \n",
    "    id_column=\"key\",  \n",
    "    timestamp_column=\"datetime\", \n",
    "    target=\"target\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7718ad-0fc2-4043-bed3-29be255a1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b77bc-84b8-4956-a81e-913fc24c2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6a051-8599-4217-88f5-47799c38f061",
   "metadata": {},
   "source": [
    "## Compare Actual vs Prediction\n",
    "### Merging both test_df and pred_df into one data frame (df_plot) to compare actual vs prediction\n",
    "### In this example, we are comparing target (actual) vs prediction. But you can also compare with quantiles like 0.5 or 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edafbc-2a72-45d8-9981-0d71b97614b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure datetime columns are datetime type\n",
    "pred_df[\"datetime\"] = pd.to_datetime(pred_df[\"datetime\"])\n",
    "test_df[\"datetime\"] = pd.to_datetime(test_df[\"datetime\"])\n",
    "\n",
    "# Merge dataframes on datetime and key\n",
    "df_plot = pd.merge(\n",
    "    test_df,\n",
    "    pred_df,\n",
    "    on=[\"datetime\", \"key\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(df_plot[\"datetime\"], df_plot[\"target\"], label=\"Actual\")\n",
    "plt.plot(df_plot[\"datetime\"], df_plot[\"predictions\"], label=\"Prediction\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Datetime\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771b985-c1d8-4eb2-ab47-99ef1c5edead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d9e73-b0cf-4140-878d-9f513d8ccd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
